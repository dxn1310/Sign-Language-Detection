# Sign-Language-Detection
Dataset : the dataset is made manually by collecting the images from camera using the imaage_collect.ipynb code, which is formated to a usable form by the create_dataset.ipynb.
The model is trained using the data after collecting the hand landmarks which is used to make the model 'model.pkl'
The model can detect live hand sign language and display the alphabet on the screen.
